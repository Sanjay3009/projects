{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77987,"status":"ok","timestamp":1747826056829,"user":{"displayName":"Sanjay Sankar","userId":"08403307972720677877"},"user_tz":-330},"id":"2RhF0wVIxPNv","outputId":"e61d5398-880e-4020-96da-51269e551f83"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m147.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install streamlit pyngrok ultralytics opencv-python-headless -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1747826056848,"user":{"displayName":"Sanjay Sankar","userId":"08403307972720677877"},"user_tz":-330},"id":"lyN2mqyX_02M","outputId":"1d2559ac-2642-4c0e-e134-837b81a8f8eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","from ultralytics import YOLO\n","from PIL import Image\n","import cv2\n","import numpy as np\n","\n","# Load the YOLOv8n detection model (update the path to your model file)\n","model = YOLO('best.pt')  # Replace with the path to your trained model\n","\n","# Streamlit app layout\n","st.title(\"Material Detection with YOLOv8n\")\n","st.write(\"Upload an image to detect Alucan, Glass, HDPEM, or PET with bounding boxes.\")\n","\n","# File uploader for image\n","uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","if uploaded_file is not None:\n","    # Read the image\n","    image = Image.open(uploaded_file)\n","    image_np = np.array(image)\n","    image_cv = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n","\n","    # Display the uploaded image\n","    st.image(image, caption='Uploaded Image', use_column_width=True)\n","    st.write(\"Detecting...\")\n","\n","    # Perform prediction\n","    results = model.predict(image_cv, conf=0.5)  # Adjust confidence threshold as needed\n","\n","    # Define class names\n","    class_names = ['Alucan', 'Glass', 'HDPEM', 'PET']  # Your class names\n","\n","    # Check for detections\n","    if results[0].boxes is not None and len(results[0].boxes) > 0:\n","        # Draw bounding boxes and labels on the image\n","        for box in results[0].boxes:\n","            # Get box coordinates, class, and confidence\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n","            class_idx = int(box.cls)  # Class index\n","            conf = box.conf.item()  # Confidence score\n","            label = f\"{class_names[class_idx]}: {conf:.2f}\"\n","\n","            # Draw rectangle and label\n","            cv2.rectangle(image_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n","            cv2.putText(image_cv, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","        # Convert back to RGB for display\n","        image_annotated = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n","\n","        # Display the annotated image\n","        st.image(image_annotated, caption='Detected Objects', use_column_width=True)\n","\n","        # List detected objects\n","        st.write(\"**Detected Objects**:\")\n","        for box in results[0].boxes:\n","            class_idx = int(box.cls)\n","            conf = box.conf.item()\n","            st.write(f\"- {class_names[class_idx]} (Confidence: {conf:.2f})\")\n","    else:\n","        st.error(\"No objects detected in the image.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"dY99cF3p_34g","outputId":"f78fdb48-d994-4289-e3fa-e3860bbca9d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","Streamlit app is live at: NgrokTunnel: \"https://a3cd-34-125-218-93.ngrok-free.app\" -> \"http://localhost:8501\"\n","\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.218.93:8501\u001b[0m\n","\u001b[0m\n","Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","2025-05-21 11:14:35.029 Examining the path of torch.classes raised:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n","    if asyncio.get_running_loop().is_running():\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","RuntimeError: no running event loop\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n","    potential_paths = extract_paths(module)\n","                      ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n","    lambda m: list(m.__path__._path),\n","                   ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n","    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n","2025-05-21 11:14:42.462 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n","\n","0: 640x640 1 Glass, 301.1ms\n","Speed: 22.3ms preprocess, 301.1ms inference, 26.1ms postprocess per image at shape (1, 3, 640, 640)\n","2025-05-21 11:14:47.056 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n","2025-05-21 11:14:47.277 Examining the path of torch.classes raised:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n","    if asyncio.get_running_loop().is_running():\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","RuntimeError: no running event loop\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n","    potential_paths = extract_paths(module)\n","                      ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n","    lambda m: list(m.__path__._path),\n","                   ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n","    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"]}],"source":["from pyngrok import ngrok\n","\n","# Set ngrok authtoken (replace with your actual authtoken)\n","!ngrok authtoken \"2w082XSHzJcB0qdg9zDKWdeRh7p_6ak8T4bUgodbqWyZ62vCE\"  # Replace with your ngrok authtoken\n","\n","# Terminate any existing ngrok tunnels\n","ngrok.kill()\n","\n","# Start a new ngrok tunnel to the Streamlit port (8501)\n","public_url = ngrok.connect(8501)\n","print(f\"Streamlit app is live at: {public_url}\")\n","\n","# Run the Streamlit app\n","!streamlit run app.py --server.port 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I37fYLVDAC_H"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2061,"status":"ok","timestamp":1747716440814,"user":{"displayName":"Sanjay Sankar","userId":"08403307972720677877"},"user_tz":-330},"id":"FgcOX82RAcKf","outputId":"3979f8a4-69ff-4bca-c827-13de768da3b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["detect\n"]}],"source":["from ultralytics import YOLO\n","model = YOLO('best.pt')\n","print(model.task)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4jxFFxTBHmf"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}