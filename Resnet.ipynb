{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhAS8G9-V9O_",
        "outputId": "edeaa932-eb3c-47a0-e529-8ecd49f77eee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "from pycocotools.coco import COCO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from pathlib import Path\n",
        "\n",
        "# Custom Dataset for COCO\n",
        "class WasteCocoDataset(Dataset):\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.coco = COCO(annotation_file)\n",
        "        self.transform = transform\n",
        "        self.image_ids = self.coco.getImgIds()\n",
        "        self.cat_id_to_label = {cat['id']: idx for idx, cat in enumerate(self.coco.loadCats(self.coco.getCatIds()))}\n",
        "        self.label_to_name = {idx: cat['name'] for idx, cat in enumerate(self.coco.loadCats(self.coco.getCatIds()))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "        if not anns:\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "        label = self.cat_id_to_label[anns[0]['category_id']]\n",
        "\n",
        "        transformed_image = self.transform(image) if self.transform else image\n",
        "\n",
        "        return transformed_image, label, image, img_info, anns"
      ],
      "metadata": {
        "id": "CwUytdVUXoF-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate function\n",
        "def custom_collate(batch):\n",
        "    transformed_images = [item[0] for item in batch]\n",
        "    labels = [item[1] for item in batch]\n",
        "    raw_images = [item[2] for item in batch]\n",
        "    img_infos = [item[3] for item in batch]\n",
        "    anns = [item[4] for item in batch]\n",
        "\n",
        "    transformed_images = torch.stack(transformed_images)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return transformed_images, labels, raw_images, img_infos, anns\n",
        "\n",
        "# Data transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets with oversampling\n",
        "def load_datasets(image_dir, annotation_file):\n",
        "    dataset = WasteCocoDataset(image_dir, annotation_file, transform=None)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataset.dataset.transform = train_transforms\n",
        "    val_dataset.dataset.transform = val_transforms\n",
        "\n",
        "    # Oversample minority classes\n",
        "    class_counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
        "    for idx in train_dataset.indices:\n",
        "        _, label, _, _, _ = dataset[idx]\n",
        "        class_counts[label] += 1\n",
        "    weights = [1.0 / class_counts[dataset[idx][1]] for idx in train_dataset.indices]\n",
        "    sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4, collate_fn=custom_collate)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, collate_fn=custom_collate)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Initialize model (ResNet-50 or EfficientNet-B0)\n",
        "def initialize_model(num_classes=4):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.layer3.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model.layer4.parameters():\n",
        "        param.requires_grad = True\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(model.fc.in_features, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BUS1bgS-d9Vx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.alpha is not None:\n",
        "            focal_loss = self.alpha[targets] * focal_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        return focal_loss.sum()"
      ],
      "metadata": {
        "id": "38V44cOcolIE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Focal loss with class weights\n",
        "    dataset = train_loader.dataset.dataset\n",
        "    class_counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
        "    for _, label, _, _, _ in dataset:\n",
        "        class_counts[label] += 1\n",
        "    total = sum(class_counts.values())\n",
        "    alpha = torch.tensor([total / (4 * class_counts[i]) for i in range(4)], dtype=torch.float).to(device)\n",
        "    criterion = FocalLoss(gamma=2.0, alpha=alpha)\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.layer3.parameters(), 'lr': 0.00005},\n",
        "        {'params': model.layer4.parameters(), 'lr': 0.0001},\n",
        "        {'params': model.fc.parameters(), 'lr': 0.001}\n",
        "    ], weight_decay=0.01)\n",
        "\n",
        "\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels, _, _, _ in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _, _, _ in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss_plot.png')\n",
        "\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    return model, best_val_loss"
      ],
      "metadata": {
        "id": "a3aLENNmoumg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bounding_boxes(model, test_loader, output_dir=\"output\", svm=None, scaler=None, max_images=100):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    class_names = ['Alucan', 'Glass', 'HDPEM', 'PET']\n",
        "\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels, raw_images, img_infos, anns in test_loader:\n",
        "            images = images.to(device)\n",
        "            if svm is not None:\n",
        "                feats = model.conv1(images)\n",
        "                feats = model.bn1(feats)\n",
        "                feats = model.relu(feats)\n",
        "                feats = model.maxpool(feats)\n",
        "                for layer in [model.layer1, model.layer2, model.layer3, model.layer4]:\n",
        "                    feats = layer(feats)\n",
        "                feats = model.avgpool(feats)\n",
        "                feats = feats.view(feats.size(0), -1)\n",
        "                feats = feats.cpu().numpy()\n",
        "                feats = scaler.transform(feats)\n",
        "                scores = svm.predict_proba(feats)\n",
        "                predictions = svm.predict(feats)\n",
        "            else:\n",
        "                outputs = model(images)\n",
        "                scores = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "                _, predictions = torch.max(outputs, 1)\n",
        "                predictions = predictions.cpu().numpy()\n",
        "\n",
        "            for i in range(len(raw_images)):\n",
        "                if count >= max_images:\n",
        "                    return\n",
        "\n",
        "                fig, ax = plt.subplots(1)\n",
        "                raw_image = raw_images[i]\n",
        "                ax.imshow(raw_image)\n",
        "\n",
        "                for ann in anns[i]:\n",
        "                    bbox = ann['bbox']\n",
        "                    x, y, w, h = bbox\n",
        "                    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "                    # Use ground truth category_id for bounding box label\n",
        "                    category_id = ann['category_id'] - 1  # Adjust for 0-based indexing\n",
        "                    true_label = class_names[category_id]\n",
        "                    # Use predicted confidence for the image-level prediction\n",
        "                    confidence = scores[i][predictions[i]]\n",
        "                    label_text = f'{true_label}: {confidence:.2f}'\n",
        "                    ax.text(x, y - 10, label_text, color='white', fontsize=10,\n",
        "                            bbox=dict(facecolor='red', alpha=0.5, pad=2))\n",
        "\n",
        "                output_path = os.path.join(output_dir, f\"test_image_{count}.png\")\n",
        "                plt.axis('off')\n",
        "                plt.savefig(output_path, bbox_inches='tight')\n",
        "                plt.close()\n",
        "                count += 1\n",
        "                print(f\"Saved visualization: {output_path}\")"
      ],
      "metadata": {
        "id": "SH5xWv5eo8FB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "def test_model(model, test_loader, svm=None, scaler=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _, _, _ in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            if svm is not None:\n",
        "                feats = model.conv1(images)\n",
        "                feats = model.bn1(feats)\n",
        "                feats = model.relu(feats)\n",
        "                feats = model.maxpool(feats)\n",
        "                for layer in [model.layer1, model.layer2, model.layer3, model.layer4]:\n",
        "                    feats = layer(feats)\n",
        "                feats = model.avgpool(feats)\n",
        "                feats = feats.view(feats.size(0), -1)\n",
        "                feats = feats.cpu().numpy()\n",
        "                feats = scaler.transform(feats)\n",
        "                predicted = torch.tensor(svm.predict(feats)).to(device)\n",
        "            else:\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "MXBnr-lKpCku"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metrics(model, test_loader, output_dir=\"output\", svm=None, scaler=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    class_names = ['Alucan', 'Glass', 'HDPEM', 'PET']\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _, _, _ in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            if svm is not None:\n",
        "                feats = model.conv1(images)\n",
        "                feats = model.bn1(feats)\n",
        "                feats = model.relu(feats)\n",
        "                feats = model.maxpool(feats)\n",
        "                for layer in [model.layer1, model.layer2, model.layer3, model.layer4]:\n",
        "                    feats = layer(feats)\n",
        "                feats = model.avgpool(feats)\n",
        "                feats = feats.view(feats.size(0), -1)\n",
        "                feats = feats.cpu().numpy()\n",
        "                feats = scaler.transform(feats)\n",
        "                scores = svm.predict_proba(feats)\n",
        "                preds = svm.predict(feats)\n",
        "            else:\n",
        "                outputs = model(images)\n",
        "                scores = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                preds = preds.cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "            all_scores.extend(scores)\n",
        "\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_scores = np.array(all_scores)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Precision-Recall, Precision-Confidence, Recall-Confidence Curves\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        precision, recall, thresholds = precision_recall_curve(all_labels == i, all_scores[:, i])\n",
        "\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(recall, precision, label=f'{class_name}')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(thresholds, precision[:-1], label=f'{class_name}')\n",
        "        plt.xlabel('Confidence Threshold')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Confidence Curve')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.plot(thresholds, recall[:-1], label=f'{class_name}')\n",
        "        plt.xlabel('Confidence Threshold')\n",
        "        plt.ylabel('Recall')\n",
        "        plt.title('Recall-Confidence Curve')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'pr_curves.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # ROC-AUC Curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(all_labels == i, all_scores[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC-AUC Curve')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, 'roc_auc.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # mAP@50 and mAP@95\n",
        "    map_50_scores = []\n",
        "    map_95_scores = []\n",
        "    for i in range(len(class_names)):\n",
        "        precision, recall, thresholds = precision_recall_curve(all_labels == i, all_scores[:, i])\n",
        "        precisions_at_50 = precision[np.where(thresholds >= 0.5)[0]]\n",
        "        recalls_at_50 = recall[np.where(thresholds >= 0.5)[0]]\n",
        "        precisions_at_95 = precision[np.where(thresholds >= 0.95)[0]]\n",
        "        recalls_at_95 = recall[np.where(thresholds >= 0.95)[0]]\n",
        "\n",
        "        ap_50 = np.trapz(precisions_at_50, recalls_at_50) if len(precisions_at_50) > 0 else 0\n",
        "        ap_95 = np.trapz(precisions_at_95, recalls_at_95) if len(precisions_at_95) > 0 else 0\n",
        "        map_50_scores.append(ap_50)\n",
        "        map_95_scores.append(ap_95)\n",
        "\n",
        "    map_50 = np.mean(map_50_scores)\n",
        "    map_95 = np.mean(map_95_scores)\n",
        "    print(f\"mAP@50: {map_50:.4f}\")\n",
        "    print(f\"mAP@95: {map_95:.4f}\")"
      ],
      "metadata": {
        "id": "MscE32lyhGkR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "def check_class_distribution(dataset):\n",
        "    class_counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
        "    for _, label, _, _, _ in dataset:\n",
        "        class_counts[label] += 1\n",
        "    print(\"Class Distribution:\", {dataset.label_to_name[k]: v for k, v in class_counts.items()})"
      ],
      "metadata": {
        "id": "kQfI0vqSpGbB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    image_dir = \"/content/drive/MyDrive/MiniProject/TrainYolov8CustomDataset/train1000/images\"  # Update this path\n",
        "    annotation_file = \"/content/drive/MyDrive/MiniProject/TrainYolov8CustomDataset/train1000/coco_annotations1000.json\"  # Update this path\n",
        "    test_image_dir = \"/content/drive/MyDrive/MiniProject/TrainYolov8CustomDataset/train1000/val_mix/\"  # Update this path\n",
        "    test_annotation_file = \"val_mix_annotations.json\"  # Update this path\n",
        "    output_dir = \"/content/drive/MyDrive/MiniProject/TrainYolov8CustomDataset/train1000/mix_output\"\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Check class distribution\n",
        "    full_dataset = WasteCocoDataset(image_dir, annotation_file, transform=val_transforms)\n",
        "    check_class_distribution(full_dataset)\n",
        "\n",
        "    train_loader, val_loader = load_datasets(image_dir, annotation_file)\n",
        "    test_dataset = WasteCocoDataset(test_image_dir, test_annotation_file, transform=val_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, collate_fn=custom_collate)\n",
        "\n",
        "    # Initialize and move model to device\n",
        "    model = initialize_model(num_classes=4).to(device)\n",
        "    trained_model, val_loss = train_model(model, train_loader, val_loader, num_epochs=20)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_path = os.path.join(output_dir, \"trained_model.pth\")\n",
        "    torch.save(trained_model.state_dict(), model_path)\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "    if val_loss >= 1.0:\n",
        "        print(\"Validation loss >= 1, training SVM pipeline...\")\n",
        "        svm, scaler = train_svm_pipeline(trained_model, train_loader, val_loader)\n",
        "        plot_bounding_boxes(trained_model, test_loader, output_dir, svm, scaler, max_images=100)\n",
        "        evaluate_metrics(trained_model, test_loader, output_dir, svm, scaler)\n",
        "        test_accuracy = test_model(trained_model, test_loader, svm, scaler)\n",
        "    else:\n",
        "        print(\"Validation loss < 1, testing directly...\")\n",
        "        plot_bounding_boxes(trained_model, test_loader, output_dir, max_images=100)\n",
        "        evaluate_metrics(trained_model, test_loader, output_dir)\n",
        "        test_accuracy = test_model(trained_model, test_loader)\n",
        "\n",
        "    print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dk3hSJMWety0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Urh3k0OSBHYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}